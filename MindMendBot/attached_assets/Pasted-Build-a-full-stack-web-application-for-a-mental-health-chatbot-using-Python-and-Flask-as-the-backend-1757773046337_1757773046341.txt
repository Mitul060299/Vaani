Build a full-stack web application for a mental health chatbot using Python and Flask as the backend framework. The app should run on Replit, handle user sessions for chat history, and include a simple HTML frontend with JavaScript for handling text input, voice recording (using browser MediaRecorder for 5-second audio clips), and facial + voice capture (using getUserMedia for camera and mic, capturing a photo via canvas and 5-second audio). The backend should process inputs, analyze them using various AI models from Hugging Face Transformers, generate empathetic responses, and return text replies along with base64-encoded MP3 audio for TTS playback using gTTS.

Key requirements:
- Use Flask with session management (secret_key) for per-user chat history (store up to 3 previous messages).
- Support three input modes via buttons on the frontend:
  - Text mode: User types a message and submits.
  - Voice mode: Records 5 seconds of audio, saves as WAV, transcribes using speech_recognition with Google recognizer, analyzes voice emotion.
  - Facial + Voice mode: Records 5 seconds of audio and captures a photo (as JPG), transcribes audio, analyzes both voice and facial emotions.
- If transcription fails, fallback to "[Voice not transcribed]".
- Temporarily save audio/image files for processing, then delete them.
- Frontend: Include a chat div for message history, input field, buttons for modes, and an audio element for autoplaying responses.

Core logic (replicate exactly from the provided code structure):
- Device setup: Use torch.device("cuda" if available else "cpu").
- Imports: Include os, time, base64, tempfile, random, numpy, pandas, torch, torch.nn.functional, gTTS, speech_recognition, transformers (various Auto* classes), sentence_transformers, faiss, cv2, PIL.Image, flask (Flask, request, jsonify, session, send_file), secrets.
- Safety helpers: is_safe_response (checks unsafe keywords), deduplicate_response (avoids duplicates).
- Model loading with primaries and fallbacks (use try-except):
  - Generation: microsoft/phi-3-mini-4k-instruct or google/gemma-2b-it, with generate_from_model function (max_new_tokens=150, temperature=0.7, top_p=0.9, safety check).
  - Sentiment: cardiffnlp/twitter-roberta-base-sentiment-latest or distilbert-base-uncased-finetuned-sst-2-english, with detect_sentiment (normalize to positive/negative/neutral).
  - Text emotion: j-hartmann/emotion-english-distilroberta-base or bhadresh-savani/distilbert-base-uncased-emotion, with detect_text_emotion (min_confidence=0.35).
  - ABSA: yangheng/deberta-v3-base-absa-v1.1 or yangheng/bert-base-absa-v1.1, with extract_aspects (keyword-based) and detect_absa (min_confidence=0.4).
  - Toxicity: unitary/toxic-bert for detect_toxicity (threshold=0.6).
  - Unsafe check: is_unsafe_message using embeddings (all-MiniLM-L6-v2) and cosine similarity (threshold=0.65) on crisis keywords, plus toxicity.
  - Soft duplicate: soft_duplicate_filter using embeddings (sim_threshold=0.92).
  - Voice emotion: superb/hubert-base-superb-er or harshit345/xlsr-wav2vec-speech-emotion-recognition, with detect_voice_emotion (min_confidence=0.35).
  - Facial emotion: dima806/facial_emotions_image_detection, with detect_facial_emotion (min_confidence=0.35).
- Embeddings: Use sentence_transformers "all-MiniLM-L6-v2" for RAG and safety.
- RAG: Load from "RAG_Knowledge_Base_WithID.xlsx" (fallback to hardcoded docs if fails), encode documents, use FAISS IndexFlatIP for retrieve_docs (top_k=3) if advice intent detected (phrases like "what should i do").
- Prompt building: build_prompt fuses history, text emotion/sentiment/ABSA, voice/facial lines (adjust response tone based on emotion, e.g., extra empathy for sad), RAG if applicable. Keep replies concise (1-3 sentences).
- Response pipeline: generate_response_pipeline checks unsafe, detects all analyses, builds prompt, generates, filters duplicates, adds facial note if applicable.
- TTS: generate_audio_base64 saves MP3 temporarily, encodes to base64.
- Crisis message: If unsafe, return predefined helpline message.
- Routes:
  - /: HTML with JS for appendMessage, playAudio, sendText (POST to /process_text with JSON), recordVoice (POST FormData audio to /process_voice), captureFaceVoice (POST FormData audio and image to /process_face_voice).
  - Process routes: Handle files, transcribe, analyze, generate reply, append to session history, return JSON with reply and audio base64.
- Run app on host='0.0.0.0', port=8080.

Ensure the app is safe, empathetic, and encourages professional help. Start with full app build mode for comprehensive implementation. If needed, provide an initial task list for review before building.